name: üè• CI/CD Pipeline - –ö–ª–∏–Ω–∏–∫–∞ (Unified)

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    - cron: '0 2 * * *'  # –ï–∂–µ–¥–Ω–µ–≤–Ω–æ –≤ 2:00
  workflow_dispatch:  # –†—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫

env:
  PYTHON_VERSION: '3.11.10'
  NODE_VERSION: '20'
  DATABASE_URL: 'postgresql+psycopg://clinic:clinicpwd@localhost:5432/clinicdb'
  CORS_DISABLE: '1'
  WS_DEV_ALLOW: '1'

jobs:
  # --- –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞ ---
  code-quality:
    name: üîç –ö–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    steps:
    - uses: actions/checkout@v4
    
    - name: üêç –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
      run: |
        cd backend
        pip install --upgrade pip
        pip install -r requirements.txt
        pip install black isort flake8 ruff vulture bandit mypy radon pydocstyle pylint
    
    - name: üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
      run: |
        cd backend
        echo "üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã..."
        if [ ! -f "pyproject.toml" ]; then
          echo "‚ùå pyproject.toml –Ω–µ –Ω–∞–π–¥–µ–Ω"
          exit 1
        fi
        echo "‚úÖ pyproject.toml –Ω–∞–π–¥–µ–Ω"
        echo "üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞:"
        ls -la app/ | head -10 || echo "‚ö†Ô∏è –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è app –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
    
    - name: üé® –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–¥–∞
      run: |
        cd backend
        set +e  # –ù–µ –≤—ã—Ö–æ–¥–∏—Ç—å –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏—Ö –≤—Ä—É—á–Ω—É—é
        
        echo "üé® –ü—Ä–æ–≤–µ—Ä—è–µ–º black —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ (—Ç–æ–ª—å–∫–æ app/ –∏ tests/)..."
        BLACK_ERRORS=0
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        for dir in app tests; do
          if [ -d "$dir" ]; then
            echo "  –ü—Ä–æ–≤–µ—Ä—è–µ–º $dir/..."
            if ! black "$dir" --check --diff 2>&1 | tee /tmp/black_${dir}.log; then
              echo "‚ö†Ô∏è $dir/ —Ç—Ä–µ–±—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"
              BLACK_ERRORS=$((BLACK_ERRORS + 1))
            fi
          fi
        done
        
        if [ $BLACK_ERRORS -gt 0 ]; then
          echo "‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ $BLACK_ERRORS –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π, —Ç—Ä–µ–±—É—é—â–∏—Ö —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"
          echo "‚ÑπÔ∏è –ù–µ –±–ª–æ–∫–∏—Ä—É–µ–º pipeline –Ω–∞ —ç—Ç–∞–ø–µ –º–∏–≥—Ä–∞—Ü–∏–∏ legacy-—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"
          echo "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: black app/ tests/"
        else
          echo "‚úÖ Black —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ OK"
        fi
        
        echo "üì¶ –ü—Ä–æ–≤–µ—Ä—è–µ–º isort —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫—É –∏–º–ø–æ—Ä—Ç–æ–≤..."
        ISORT_ERRORS=0
        
        for dir in app tests; do
          if [ -d "$dir" ]; then
            echo "  –ü—Ä–æ–≤–µ—Ä—è–µ–º $dir/..."
            if ! isort "$dir" --check-only --diff 2>&1 | tee /tmp/isort_${dir}.log; then
              echo "‚ö†Ô∏è $dir/ —Ç—Ä–µ–±—É–µ—Ç —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –∏–º–ø–æ—Ä—Ç–æ–≤"
              ISORT_ERRORS=$((ISORT_ERRORS + 1))
            fi
          fi
        done
        
        if [ $ISORT_ERRORS -gt 0 ]; then
          echo "‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ $ISORT_ERRORS –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π, —Ç—Ä–µ–±—É—é—â–∏—Ö —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏ –∏–º–ø–æ—Ä—Ç–æ–≤"
          echo "‚ÑπÔ∏è –ù–µ –±–ª–æ–∫–∏—Ä—É–µ–º pipeline –Ω–∞ —ç—Ç–∞–ø–µ –º–∏–≥—Ä–∞—Ü–∏–∏ legacy-–∏–º–ø–æ—Ä—Ç–æ–≤"
          echo "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: isort app/ tests/"
        else
          echo "‚úÖ Isort —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ OK"
        fi
    
    - name: üîç –õ–∏–Ω—Ç–∏–Ω–≥ –∏ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
      run: |
        cd backend
        set +e  # –ù–µ –≤—ã—Ö–æ–¥–∏—Ç—å –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö, —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –æ—à–∏–±–∫–∏
        mkdir -p quality-reports
        
        echo "üîç –°–æ–±–∏—Ä–∞–µ–º –í–°–ï –æ—à–∏–±–∫–∏ –ª–∏–Ω—Ç–∏–Ω–≥–∞ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞..."
        echo "–≠—Ç–æ—Ç —à–∞–≥ –±–ª–æ–∫–∏—Ä—É–µ—Ç pipeline –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –æ—à–∏–±–æ–∫"
        
        # Ruff - —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –æ—à–∏–±–∫–∏
        echo "üîç Ruff - –±—ã—Å—Ç—Ä—ã–π –ª–∏–Ω—Ç–µ—Ä (—Ç–æ–ª—å–∫–æ app/ –∏ tests/)..."
        RUFF_ERRORS=0
        RUFF_TOTAL=0
        
        for dir in app tests; do
          if [ -d "$dir" ]; then
            echo "  –ü—Ä–æ–≤–µ—Ä—è–µ–º $dir/..."
            ruff check "$dir" --select=E9,F63,F7 --output-format=concise > quality-reports/ruff_${dir}.txt 2>&1
            RUFF_EXIT=$?
            if [ $RUFF_EXIT -ne 0 ]; then
              ERROR_COUNT=$(grep -c "^" quality-reports/ruff_${dir}.txt || echo "0")
              RUFF_TOTAL=$((RUFF_TOTAL + ERROR_COUNT))
              RUFF_ERRORS=$((RUFF_ERRORS + 1))
              echo "  ‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ –æ—à–∏–±–æ–∫ –≤ $dir/: $ERROR_COUNT"
            else
              echo "  ‚úÖ $dir/ OK"
            fi
          fi
        done
        
        # Flake8 - —Å–æ–±–∏—Ä–∞–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏
        echo "üîç Flake8 - –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ (—Ç–æ–ª—å–∫–æ app/)..."
        FLAKE8_ERRORS=0
        if [ -d "app" ]; then
          flake8 app --select=E9,F63,F7,F82 --show-source --statistics > quality-reports/flake8.txt 2>&1
          FLAKE8_EXIT=$?
          if [ $FLAKE8_EXIT -ne 0 ]; then
            ERROR_COUNT=$(grep -c "^" quality-reports/flake8.txt || echo "0")
            FLAKE8_ERRORS=$ERROR_COUNT
            echo "  ‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫: $ERROR_COUNT"
          else
            echo "  ‚úÖ Flake8 OK"
          fi
        fi
        
        # MyPy - —Å–æ–±–∏—Ä–∞–µ–º –æ—à–∏–±–∫–∏ —Ç–∏–ø–æ–≤
        echo "üîç MyPy - –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–∏–ø–æ–≤ (—Ç–æ–ª—å–∫–æ app/)..."
        MYPY_ERRORS=0
        if [ -d "app" ]; then
          mypy app --ignore-missing-imports --show-error-codes > quality-reports/mypy.txt 2>&1
          MYPY_EXIT=$?
          if [ $MYPY_EXIT -ne 0 ]; then
            ERROR_COUNT=$(grep -c "error:" quality-reports/mypy.txt || echo "0")
            MYPY_ERRORS=$ERROR_COUNT
            echo "  ‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ –æ—à–∏–±–æ–∫ —Ç–∏–ø–æ–≤: $ERROR_COUNT"
          else
            echo "  ‚úÖ MyPy OK"
          fi
        fi
        
        # Pylint - —Å–æ–±–∏—Ä–∞–µ–º –æ—à–∏–±–∫–∏
        echo "üîç Pylint - –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (—Ç–æ–ª—å–∫–æ app/)..."
        PYLINT_ERRORS=0
        if [ -d "app" ]; then
          pylint app --disable=all --enable=E0602,E0603,E1120,E1121 > quality-reports/pylint.txt 2>&1
          PYLINT_EXIT=$?
          if [ $PYLINT_EXIT -ne 0 ]; then
            ERROR_COUNT=$(grep -c "^" quality-reports/pylint.txt || echo "0")
            PYLINT_ERRORS=$ERROR_COUNT
            echo "  ‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ –æ—à–∏–±–æ–∫: $ERROR_COUNT"
          else
            echo "  ‚úÖ Pylint OK"
          fi
        fi
        
        # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç
        echo ""
        echo "üìä –°–í–û–î–ù–´–ô –û–¢–ß–ï–¢ –û–ë –û–®–ò–ë–ö–ê–•:"
        echo "================================"
        echo "Ruff: $RUFF_TOTAL –æ—à–∏–±–æ–∫ –≤ $RUFF_ERRORS –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ö"
        echo "Flake8: $FLAKE8_ERRORS –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫"
        echo "MyPy: $MYPY_ERRORS –æ—à–∏–±–æ–∫ —Ç–∏–ø–æ–≤"
        echo "Pylint: $PYLINT_ERRORS –æ—à–∏–±–æ–∫"
        TOTAL=$((RUFF_TOTAL + FLAKE8_ERRORS + MYPY_ERRORS + PYLINT_ERRORS))
        BLOCKING_TOTAL=$((RUFF_TOTAL + FLAKE8_ERRORS))
        echo "–í–°–ï–ì–û: $TOTAL –æ—à–∏–±–æ–∫"
        echo "–ë–õ–û–ö–ò–†–£–Æ–©–ò–•: $BLOCKING_TOTAL (Ruff + Flake8)"
        echo "================================"
        
        # –°–æ–∑–¥–∞–µ–º –µ–¥–∏–Ω—ã–π —Ñ–∞–π–ª —Å–æ –≤—Å–µ–º–∏ –æ—à–∏–±–∫–∞–º–∏
        echo "üìù –°–æ–∑–¥–∞–µ–º –µ–¥–∏–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ –≤—Å–µ–º–∏ –æ—à–∏–±–∫–∞–º–∏..."
        {
          echo "# –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –æ–± –æ—à–∏–±–∫–∞—Ö –ª–∏–Ω—Ç–∏–Ω–≥–∞"
          echo "–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: $(date)"
          echo ""
          echo "## –°–≤–æ–¥–∫–∞"
          echo "- Ruff: $RUFF_TOTAL –æ—à–∏–±–æ–∫"
          echo "- Flake8: $FLAKE8_ERRORS –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫"
          echo "- MyPy: $MYPY_ERRORS –æ—à–∏–±–æ–∫ —Ç–∏–ø–æ–≤"
          echo "- Pylint: $PYLINT_ERRORS –æ—à–∏–±–æ–∫"
          echo "- **–í–°–ï–ì–û: $TOTAL –æ—à–∏–±–æ–∫**"
          echo "- **–ë–õ–û–ö–ò–†–£–Æ–©–ò–•: $BLOCKING_TOTAL (Ruff + Flake8)**"
          echo ""
          
          if [ $RUFF_ERRORS -gt 0 ]; then
            echo "## Ruff –æ—à–∏–±–∫–∏"
            echo ""
            for dir in app tests; do
              if [ -f "quality-reports/ruff_${dir}.txt" ] && [ -s "quality-reports/ruff_${dir}.txt" ]; then
                echo "### $dir/"
                echo "\`\`\`"
                cat quality-reports/ruff_${dir}.txt
                echo "\`\`\`"
                echo ""
              fi
            done
          fi
          
          if [ $FLAKE8_ERRORS -gt 0 ]; then
            echo "## Flake8 –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏"
            echo "\`\`\`"
            cat quality-reports/flake8.txt
            echo "\`\`\`"
            echo ""
          fi
          
          if [ $MYPY_ERRORS -gt 0 ]; then
            echo "## MyPy –æ—à–∏–±–∫–∏ —Ç–∏–ø–æ–≤"
            echo "\`\`\`"
            head -200 quality-reports/mypy.txt
            echo "\`\`\`"
            echo ""
          fi
          
          if [ $PYLINT_ERRORS -gt 0 ]; then
            echo "## Pylint –æ—à–∏–±–∫–∏"
            echo "\`\`\`"
            head -100 quality-reports/pylint.txt
            echo "\`\`\`"
            echo ""
          fi
        } > quality-reports/ALL_ERRORS_REPORT.md
        
        echo "‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ quality-reports/ALL_ERRORS_REPORT.md"
        echo "üì¶ –í—Å–µ –æ—Ç—á–µ—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ quality-reports/"
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É
        if [ $BLOCKING_TOTAL -gt 0 ]; then
          echo ""
          echo "‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ù–∞–π–¥–µ–Ω–æ $TOTAL –æ—à–∏–±–æ–∫ (–±–ª–æ–∫–∏—Ä—É—é—â–∏—Ö: $BLOCKING_TOTAL)!"
          echo "üìÑ –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç: quality-reports/ALL_ERRORS_REPORT.md"
          echo "üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –ò—Å–ø—Ä–∞–≤—å—Ç–µ –≤—Å–µ –æ—à–∏–±–∫–∏ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º –∫–æ–º–º–∏—Ç–æ–º"
          echo ""
          echo "–î–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ:"
          echo "  cd backend"
          echo "  python scripts/collect_linting_errors.py"
          echo ""
          echo "‚ùå –ë–ª–æ–∫–∏—Ä—É–µ–º pipeline –∏–∑-–∑–∞ Ruff/Flake8 –æ—à–∏–±–æ–∫"
          exit 1
        else
          if [ $TOTAL -gt 0 ]; then
            echo "‚úÖ –ë–ª–æ–∫–∏—Ä—É—é—â–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã. MyPy/Pylint –æ—à–∏–±–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –æ—Ç—á–µ—Ç–µ (–Ω–µ –±–ª–æ–∫–∏—Ä—É—é—Ç)."
          else
            echo "‚úÖ –í—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!"
          fi
        fi
    
    - name: üìÑ –°–æ–∑–¥–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å –æ—à–∏–±–∫–∞–º–∏
      if: always()
      run: |
        cd backend
        if [ -f "quality-reports/ALL_ERRORS_REPORT.md" ]; then
          echo "üìÑ –î–æ–∫—É–º–µ–Ω—Ç —Å –æ—à–∏–±–∫–∞–º–∏ —Å–æ–∑–¥–∞–Ω"
          echo "üìä –†–∞–∑–º–µ—Ä: $(wc -l < quality-reports/ALL_ERRORS_REPORT.md) —Å—Ç—Ä–æ–∫"
          echo ""
          echo "## üìã –û—Ç—á–µ—Ç –æ–± –æ—à–∏–±–∫–∞—Ö –ª–∏–Ω—Ç–∏–Ω–≥–∞" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          head -50 quality-reports/ALL_ERRORS_REPORT.md >> $GITHUB_STEP_SUMMARY
          if [ $(wc -l < quality-reports/ALL_ERRORS_REPORT.md) -gt 50 ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "... (–ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç –≤ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞—Ö)" >> $GITHUB_STEP_SUMMARY
          fi
        else
          echo "‚úÖ –û—à–∏–±–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ - –¥–æ–∫—É–º–µ–Ω—Ç –Ω–µ —Å–æ–∑–¥–∞–Ω"
        fi
    
    - name: üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∫–æ–¥–∞
      run: |
        cd backend
        mkdir -p quality-reports
        echo "üìä –ê–Ω–∞–ª–∏–∑ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∫–æ–¥–∞ (Radon)..."
        radon cc app --min B --show-complexity > quality-reports/complexity.txt 2>&1 || true
        radon mi app --min B > quality-reports/maintainability.txt 2>&1 || true
        
        echo "üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏:"
        head -30 quality-reports/complexity.txt || true
        echo ""
        echo "üìä –ò–Ω–¥–µ–∫—Å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ—Å—Ç–∏:"
        head -20 quality-reports/maintainability.txt || true
    
    - name: üìù –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
      run: |
        cd backend
        mkdir -p quality-reports
        echo "üìù –ü—Ä–æ–≤–µ—Ä–∫–∞ docstrings (pydocstyle)..."
        pydocstyle app --convention=google --add-ignore=D100,D104 > quality-reports/docstyle.txt 2>&1 || {
          echo "‚ö†Ô∏è –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –Ω–µ –∏–º–µ—é—Ç docstrings (–Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º):"
          cat quality-reports/docstyle.txt | head -30
        }
    
    - name: üîç –ü–æ–∏—Å–∫ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
      run: |
        cd backend
        mkdir -p quality-reports
        set -e
        
        echo "üîç –ü–æ–∏—Å–∫ TODO/FIXME/HACK –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤..."
        grep -r "TODO\|FIXME\|HACK\|XXX" app/ --include="*.py" > quality-reports/todos.txt 2>&1 || echo "‚úÖ –ù–µ—Ç TODO/FIXME –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤"
        if [ -s quality-reports/todos.txt ]; then
          echo "‚ö†Ô∏è –ù–∞–π–¥–µ–Ω—ã TODO/FIXME –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏:"
          head -20 quality-reports/todos.txt
        fi
        
        echo "üîç –ü–æ–∏—Å–∫ –º–µ—Ä—Ç–≤–æ–≥–æ –∫–æ–¥–∞ (Vulture)..."
        vulture app --min-confidence 80 --exclude app/api/v1/endpoints/ > quality-reports/vulture.txt 2>&1 || {
          echo "‚ö†Ô∏è Vulture –Ω–∞—à–µ–ª –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –º–µ—Ä—Ç–≤—ã–π –∫–æ–¥ (–Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º):"
          head -30 quality-reports/vulture.txt
        }
        
        echo "üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–æ–≤..."
        find app -name "*.py" -type f -exec wc -l {} + | sort -rn | head -20 > quality-reports/large-files.txt || true
        echo "üìä –°–∞–º—ã–µ –±–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã:"
        head -10 quality-reports/large-files.txt
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã –±–æ–ª—å—à–µ 1000 —Å—Ç—Ä–æ–∫
        if find app -name "*.py" -type f -exec wc -l {} + | awk '$1 > 1000 {print $2}' | grep -q .; then
          echo "‚ö†Ô∏è –ù–∞–π–¥–µ–Ω—ã —Ñ–∞–π–ª—ã –±–æ–ª—å—à–µ 1000 —Å—Ç—Ä–æ–∫:"
          find app -name "*.py" -type f -exec wc -l {} + | awk '$1 > 1000 {print $1, $2}'
        fi
    
    - name: üîí –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
      run: |
        cd backend
        mkdir -p quality-reports
        echo "üîí Bandit - —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏..."
        bandit -r app -f json -o quality-reports/bandit.json > quality-reports/bandit.txt 2>&1 || {
          echo "‚ùå Bandit –Ω–∞—à–µ–ª –ø—Ä–æ–±–ª–µ–º—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏:"
          cat quality-reports/bandit.txt | head -50
          # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –≤—ã—Å–æ–∫–∏–π –∏ —Å—Ä–µ–¥–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å
          if grep -q "Severity: High\|Severity: Medium" quality-reports/bandit.txt; then
            echo "‚ùå –ù–∞–π–¥–µ–Ω—ã –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"
            exit 1
          fi
        }
        echo "‚úÖ Bandit –ø—Ä–æ–≤–µ—Ä–∫–∞ OK"
    
    - name: üì§ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–æ–≤
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: code-quality-reports
        path: backend/quality-reports/
        retention-days: 7
        if-no-files-found: warn
    
    - name: üìä –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
      if: always()
      run: |
        cd backend
        echo "## üìä –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç –∫–∞—á–µ—Å—Ç–≤–∞ –∫–æ–¥–∞" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã:" >> $GITHUB_STEP_SUMMARY
        echo "- Black —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ" >> $GITHUB_STEP_SUMMARY
        echo "- Isort —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∏–º–ø–æ—Ä—Ç–æ–≤" >> $GITHUB_STEP_SUMMARY
        echo "- Ruff –ª–∏–Ω—Ç–∏–Ω–≥" >> $GITHUB_STEP_SUMMARY
        echo "- Flake8 –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏" >> $GITHUB_STEP_SUMMARY
        echo "- Bandit –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        if [ -f quality-reports/todos.txt ] && [ -s quality-reports/todos.txt ]; then
          echo "### ‚ö†Ô∏è –ù–∞–π–¥–µ–Ω—ã TODO/FIXME:" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          head -10 quality-reports/todos.txt >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
        fi
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "üì¶ –û—Ç—á–µ—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –∫–∞–∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã" >> $GITHUB_STEP_SUMMARY

  # --- Frontend —Ç–µ—Å—Ç—ã ---
  frontend-tests:
    name: üé® Frontend —Ç–µ—Å—Ç—ã
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - uses: actions/checkout@v4
    
    - name: üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
    
    - name: üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
      run: |
        cd frontend
        npm ci
    
    - name: üîç –õ–∏–Ω—Ç–∏–Ω–≥ frontend
      run: |
        cd frontend
        if npm run lint:check; then
          echo "‚úÖ Frontend lint passed"
        else
          echo "::warning::Frontend lint has legacy violations and is non-blocking in this phase. Frontend tests/build remain blocking."
        fi
    
    - name: üß™ –¢–µ—Å—Ç—ã frontend
      run: |
        cd frontend
        npm run test:run -- --coverage
    
    - name: üèóÔ∏è –°–±–æ—Ä–∫–∞ frontend
      run: |
        cd frontend
        npm run build

  # --- Backend —Ç–µ—Å—Ç—ã ---
  backend-tests:
    name: üêç Backend —Ç–µ—Å—Ç—ã
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: code-quality
    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_DB: clinicdb
          POSTGRES_USER: clinic
          POSTGRES_PASSWORD: clinicpwd
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U clinic -d clinicdb"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10
    env:
      DATABASE_URL: postgresql+psycopg://clinic:clinicpwd@localhost:5432/clinicdb
      CORS_DISABLE: '1'
      WS_DEV_ALLOW: '1'
      PYTHONIOENCODING: 'utf-8'
      PYTHONUTF8: '1'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: üêç –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
      run: |
        cd backend
        pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-asyncio httpx
    
    - name: üóÑÔ∏è –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
      run: |
        cd backend
        echo "‚è≥ –û–∂–∏–¥–∞–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å Postgres..."
        python - <<'PY'
        import os
        import time
        from sqlalchemy import create_engine, text

        url = os.environ["DATABASE_URL"]
        engine = create_engine(url)
        for i in range(30):
            try:
                with engine.connect() as conn:
                    conn.execute(text("SELECT 1"))
                print("‚úÖ Postgres ready")
                break
            except Exception as e:
                if i == 29:
                    raise
                print(f"Attempt {i + 1}/30: {e}")
                time.sleep(2)
        PY
        alembic upgrade head
        alembic current
    
    - name: üß™ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤
      run: |
        cd backend
        echo "üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é pytest:"
        cat pytest.ini
        echo "üß™ –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã —Å –ø–æ–∫—Ä—ã—Ç–∏–µ–º:"
        pytest tests/
        echo "üìÅ –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:"
        ls -la htmlcov/ || echo "–ü–∞–ø–∫–∞ htmlcov –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"
        if [ ! -d "htmlcov" ]; then
          echo "üìä –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É htmlcov –¥–ª—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤"
          mkdir -p htmlcov
          echo "Placeholder coverage report - tests completed successfully" > htmlcov/index.html
        fi

    - name: üß™ Critical E2E Smoke
      run: |
        cd backend
        echo "üî¨ –ó–∞–ø—É—Å–∫–∞–µ–º –∫—Ä–∏—Ç–∏—á–Ω—ã–µ E2E —Å—Ü–µ–Ω–∞—Ä–∏–∏ (queue/payment/rbac/emr/print)..."
        pytest -q \
          tests/integration/test_queue_time_websocket_e2e.py \
          tests/integration/test_payment_init_e2e.py \
          tests/integration/test_rbac_matrix.py \
          tests/integration/test_e2e_doctor_visit.py::TestDoctorVisitFlow::test_doctor_can_fill_emr \
          tests/integration/test_e2e_doctor_visit.py::TestDoctorVisitFlow::test_doctor_can_generate_prescription_pdf
    
    - name: üìä –ó–∞–≥—Ä—É–∑–∫–∞ –æ—Ç—á–µ—Ç–∞ –ø–æ–∫—Ä—ã—Ç–∏—è
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: coverage-report
        path: backend/htmlcov/
        if-no-files-found: warn

  # --- Security —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ ---
  security:
    name: üîí Security —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: [code-quality, frontend-tests, backend-tests]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: üêç –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
      run: |
        cd backend
        pip install --upgrade pip
        pip install -r requirements.txt
        pip install safety bandit semgrep
    
    - name: üîí –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π
      run: |
        cd backend
        # Safety –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—è—Ö
        safety check --json
        # Bandit –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∫–æ–¥–∞
        bandit -r app -f json
        # Semgrep –¥–ª—è —Å—Ç–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        semgrep --config=auto app/

  # --- Docker —Å–±–æ—Ä–∫–∞ ---
  docker:
    name: üê≥ Docker —Å–±–æ—Ä–∫–∞
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: [code-quality, frontend-tests, backend-tests]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: üê≥ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Docker Buildx
      uses: docker/setup-buildx-action@v3
    
    - name: üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ Dockerfile'–æ–≤
      run: |
        echo "üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ Dockerfile'–æ–≤..."
        ls -la ops/
        if [ ! -f "ops/backend.Dockerfile" ]; then
          echo "‚ùå Backend Dockerfile –Ω–µ –Ω–∞–π–¥–µ–Ω"
          exit 1
        fi
        if [ ! -f "ops/frontend.Dockerfile" ]; then
          echo "‚ùå Frontend Dockerfile –Ω–µ –Ω–∞–π–¥–µ–Ω"
          exit 1
        fi
        echo "‚úÖ –í—Å–µ Dockerfile'—ã –Ω–∞–π–¥–µ–Ω—ã"
    
    - name: üèóÔ∏è –°–±–æ—Ä–∫–∞ Backend Docker
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./ops/backend.Dockerfile
        push: false
        tags: clinic-backend:latest
        cache-from: type=gha
        cache-to: type=gha,mode=max
        build-args: |
          BUILDKIT_INLINE_CACHE=1
    
    - name: üèóÔ∏è –°–±–æ—Ä–∫–∞ Frontend Docker
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./ops/frontend.Dockerfile
        push: false
        tags: clinic-frontend:latest
        cache-from: type=gha
        cache-to: type=gha,mode=max
        build-args: |
          BUILDKIT_INLINE_CACHE=1

  # --- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã ---
  integration:
    name: üîó –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [backend-tests, frontend-tests]
    if: always() && (github.event_name == 'workflow_dispatch' || github.ref == 'refs/heads/main')
    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_DB: clinicdb
          POSTGRES_USER: clinic
          POSTGRES_PASSWORD: clinicpwd
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U clinic -d clinicdb"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10
    env:
      DATABASE_URL: postgresql+psycopg://clinic:clinicpwd@localhost:5432/clinicdb
      CORS_DISABLE: '1'
      WS_DEV_ALLOW: '1'
      PYTHONIOENCODING: 'utf-8'
      PYTHONUTF8: '1'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: üêç –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
      run: |
        cd backend
        pip install --upgrade pip
        pip install -r requirements.txt
        # Test dependencies
        pip install pytest pytest-asyncio httpx requests
        echo "‚úÖ –í—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã"
        echo "üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –ø–∞–∫–µ—Ç—ã:"
        pip list | grep -E "(fastapi|uvicorn|requests|httpx)" || true
    
    - name: üóÑÔ∏è –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –±–∞–∑—ã
      run: |
        cd backend
        echo "‚è≥ –û–∂–∏–¥–∞–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å Postgres..."
        python - <<'PY'
        import os
        import time
        from sqlalchemy import create_engine, text

        url = os.environ["DATABASE_URL"]
        engine = create_engine(url)
        for i in range(30):
            try:
                with engine.connect() as conn:
                    conn.execute(text("SELECT 1"))
                print("‚úÖ Postgres ready")
                break
            except Exception as e:
                if i == 29:
                    raise
                print(f"Attempt {i + 1}/30: {e}")
                time.sleep(2)
        PY
        alembic upgrade head
        alembic current
    
    - name: üöÄ –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞
      run: |
        set -e
        cd backend
        export DATABASE_URL="${DATABASE_URL}"
        export CORS_DISABLE="1"
        export WS_DEV_ALLOW="1"
        export PYTHONPATH="$GITHUB_WORKSPACE/backend:$PYTHONPATH"
        
        echo "üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –º–æ–∂–µ—Ç –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è..."
        echo "Step 1: Testing critical imports before app.main..."
        echo "  - Testing app.core.exception_handlers..."
        python -c "
        import os
        import sys
        os.environ['DATABASE_URL'] = 'postgresql+psycopg://clinic:clinicpwd@localhost:5432/clinicdb'
        os.environ['CORS_DISABLE'] = '1'
        os.environ['WS_DEV_ALLOW'] = '1'
        print('Debug: Python version:', sys.version[:5])
        print('Debug: Current dir:', os.getcwd())
        try:
            from app.core.exception_handlers import register_exception_handlers
            print('‚úÖ exception_handlers OK')
        except Exception as e:
            print('‚ùå exception_handlers failed:', e)
            import traceback
            traceback.print_exc()
        " 2>&1 || echo "‚ö†Ô∏è exception_handlers import failed"
        
        echo "  - Testing app.ws.queue_ws..."
        python -c "
        import os
        os.environ['DATABASE_URL'] = 'postgresql+psycopg://clinic:clinicpwd@localhost:5432/clinicdb'
        os.environ['CORS_DISABLE'] = '1'
        os.environ['WS_DEV_ALLOW'] = '1'
        from app.ws.queue_ws import router, ws_queue
        print('‚úÖ queue_ws OK')
        " 2>&1 || echo "‚ö†Ô∏è queue_ws import failed"
        
        echo "  - Testing app.api.deps..."
        python -c "
        import os
        os.environ['DATABASE_URL'] = 'postgresql+psycopg://clinic:clinicpwd@localhost:5432/clinicdb'
        os.environ['CORS_DISABLE'] = '1'
        os.environ['WS_DEV_ALLOW'] = '1'
        from app.api.deps import create_access_token
        print('‚úÖ deps OK')
        " 2>&1 || echo "‚ö†Ô∏è deps import failed (will use fallback)"
        
        echo "  - Testing app.api.v1.api..."
        if ! python -c "
        import os
        import sys
        import traceback
        os.environ['DATABASE_URL'] = 'postgresql+psycopg://clinic:clinicpwd@localhost:5432/clinicdb'
        os.environ['CORS_DISABLE'] = '1'
        os.environ['WS_DEV_ALLOW'] = '1'
        print('Debug: Testing api.v1.api import...')
        try:
            from app.api.v1.api import api_router
            print('‚úÖ api.v1.api OK')
        except Exception as e:
            print(f'‚ùå api.v1.api FAILED: {e}')
            print('Full traceback:')
            traceback.print_exc()
            print('sys.path first 3:', sys.path[:3])
            sys.exit(1)
        " 2>&1; then
          echo "‚ùå Failed to import app.api.v1.api - checking which endpoint module fails..."
          python -c "
          import os
          import sys
          os.environ['DATABASE_URL'] = 'postgresql+psycopg://clinic:clinicpwd@localhost:5432/clinicdb'
          os.environ['CORS_DISABLE'] = '1'
          os.environ['WS_DEV_ALLOW'] = '1'
          modules_to_test = [
              'app.api.v1.endpoints.auth',
              'app.api.v1.endpoints.patients',
              'app.api.v1.endpoints.visits',
              'app.api.v1.endpoints.services',
              'app.api.v1.endpoints.appointments',
          ]
          failed_modules = []
          for module in modules_to_test:
              try:
                  __import__(module)
                  print(f'‚úÖ {module} OK')
              except Exception as e:
                  print(f'‚ùå {module} FAILED: {e}')
                  import traceback
                  traceback.print_exc()
                  failed_modules.append(module)
          if failed_modules:
              print(f'‚ùå Failed modules: {failed_modules}')
              sys.exit(1)
          " 2>&1 || exit 1
        fi
        
        echo "Step 2: Importing app.main module..."
        if ! python -c "
        import os
        import sys
        import traceback
        os.environ['DATABASE_URL'] = 'postgresql+psycopg://clinic:clinicpwd@localhost:5432/clinicdb'
        os.environ['CORS_DISABLE'] = '1'
        os.environ['WS_DEV_ALLOW'] = '1'
        print('Debug: Testing app.main import...')
        try:
            import app.main
            print('‚úÖ app.main module imported')
        except Exception as e:
            print(f'‚ùå Failed to import app.main: {e}')
            print('Full traceback:')
            traceback.print_exc()
            sys.exit(1)
        " 2>&1; then
          echo "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å app.main"
          exit 1
        fi

        echo "Step 3: Importing app from app.main..."
        if ! python -c "
        import os
        import sys
        import traceback
        os.environ['DATABASE_URL'] = 'postgresql+psycopg://clinic:clinicpwd@localhost:5432/clinicdb'
        os.environ['CORS_DISABLE'] = '1'
        os.environ['WS_DEV_ALLOW'] = '1'
        print('Debug: Testing app from app.main import...')
        try:
            from app.main import app
            print('‚úÖ App –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ')
        except Exception as e:
            print(f'‚ùå Failed to import app from app.main: {e}')
            print('Full traceback:')
            traceback.print_exc()
            sys.exit(1)
        " 2>&1; then
          echo "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å app –∏–∑ app.main"
          exit 1
        fi
        
        echo "‚úÖ –í—Å–µ –∏–º–ø–æ—Ä—Ç—ã —É—Å–ø–µ—à–Ω—ã"
        echo "üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —Å–µ—Ä–≤–µ—Ä..."
        nohup uvicorn app.main:app --host 127.0.0.1 --port 8000 > server.log 2>&1 &
        SERVER_PID=$!
        echo $SERVER_PID > server.pid
        echo "‚è≥ –û–∂–∏–¥–∞–µ–º –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞ (PID: $SERVER_PID)..."
        sleep 15
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å –µ—â–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
        if ! kill -0 $SERVER_PID 2>/dev/null; then
          echo "‚ùå –°–µ—Ä–≤–µ—Ä –Ω–µ –∑–∞–ø—É—Å—Ç–∏–ª—Å—è (–ø—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à–∏–ª—Å—è)"
          echo "üìã –õ–æ–≥–∏ —Å–µ—Ä–≤–µ—Ä–∞:"
          cat server.log || echo "–õ–æ–≥–∏ –Ω–µ –¥–æ—Å—Ç—É–ø–Ω—ã"
          exit 1
        fi
        
        echo "üìã –õ–æ–≥–∏ —Å–µ—Ä–≤–µ—Ä–∞ –ø–æ—Å–ª–µ –∑–∞–ø—É—Å–∫–∞:"
        head -50 server.log || echo "–õ–æ–≥–∏ –Ω–µ –¥–æ—Å—Ç—É–ø–Ω—ã"
        echo "üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –ø—Ä–æ—Ü–µ—Å—Å–∞:"
        ps aux | grep uvicorn | grep -v grep || echo "–ü—Ä–æ—Ü–µ—Å—Å –Ω–µ –Ω–∞–π–¥–µ–Ω"
        if [ -f server.pid ]; then
          echo "üìù PID —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: $(cat server.pid)"
        else
          echo "‚ö†Ô∏è PID —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω"
        fi
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å–µ—Ä–≤–µ—Ä–∞
        echo "üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å–µ—Ä–≤–µ—Ä–∞..."
        for i in {1..5}; do
          if curl -f http://127.0.0.1:8000/api/v1/health > /dev/null 2>&1; then
            echo "‚úÖ –°–µ—Ä–≤–µ—Ä —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω –∏ –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å—ã"
            break
          else
            if [ $i -eq 5 ]; then
              echo "‚ùå –°–µ—Ä–≤–µ—Ä –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç –ø–æ—Å–ª–µ 5 –ø–æ–ø—ã—Ç–æ–∫"
              echo "üìã –ü–æ—Å–ª–µ–¥–Ω–∏–µ 100 —Å—Ç—Ä–æ–∫ –ª–æ–≥–æ–≤:"
              tail -100 server.log || echo "–õ–æ–≥–∏ –Ω–µ –¥–æ—Å—Ç—É–ø–Ω—ã"
              exit 1
            fi
            echo "‚è≥ –ü–æ–ø—ã—Ç–∫–∞ $i/5: —Å–µ—Ä–≤–µ—Ä –µ—â–µ –Ω–µ –≥–æ—Ç–æ–≤..."
            sleep 3
          fi
        done
    
    - name: üß™ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã
      run: |
        cd backend
        # –ñ–¥–µ–º –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞
        echo "‚è≥ –û–∂–∏–¥–∞–µ–º –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞..."
        SERVER_READY=false
        for i in {1..30}; do
          if curl -s -f "http://127.0.0.1:8000/api/v1/health" > /dev/null 2>&1; then
            echo "‚úÖ –°–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω –∏ –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å—ã"
            SERVER_READY=true
            break
          fi
          echo "‚è≥ –ü–æ–ø—ã—Ç–∫–∞ $i/30: —Å–µ—Ä–≤–µ—Ä –µ—â–µ –Ω–µ –≥–æ—Ç–æ–≤..."
          if [ $i -eq 30 ]; then
            echo "‚ùå –°–µ—Ä–≤–µ—Ä –Ω–µ –∑–∞–ø—É—Å—Ç–∏–ª—Å—è –∑–∞ 60 —Å–µ–∫—É–Ω–¥"
            echo "üìã –ü–æ—Å–ª–µ–¥–Ω–∏–µ 100 —Å—Ç—Ä–æ–∫ –ª–æ–≥–æ–≤ —Å–µ—Ä–≤–µ—Ä–∞:"
            tail -100 server.log || echo "–õ–æ–≥–∏ –Ω–µ –¥–æ—Å—Ç—É–ø–Ω—ã"
            echo "üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ—Ü–µ—Å—Å—ã:"
            ps aux | grep uvicorn || echo "–ü—Ä–æ—Ü–µ—Å—Å uvicorn –Ω–µ –Ω–∞–π–¥–µ–Ω"
            if [ -f server.pid ]; then
              echo "üìù PID —Ñ–∞–π–ª: $(cat server.pid)"
            fi
            exit 1
          fi
          sleep 2
        done
        
        if [ "$SERVER_READY" = false ]; then
          echo "‚ùå –°–µ—Ä–≤–µ—Ä –Ω–µ –≥–æ—Ç–æ–≤ –∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—é"
          exit 1
        fi
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è –∑–∞–ø—É—â–µ–Ω–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞
        echo "üß™ –ó–∞–ø—É—Å–∫–∞–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã..."
        pytest -q tests/integration/test_server_integration.py -rA || {
          echo "‚ö†Ô∏è –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –Ω–µ –ø—Ä–æ—à–ª–∏"
          echo "üìä –õ–æ–≥–∏ —Å–µ—Ä–≤–µ—Ä–∞ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 100 —Å—Ç—Ä–æ–∫):"
          tail -100 server.log || true
          exit 1
        }
    
    - name: üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞
      if: always()
      run: |
        if [ -f backend/server.pid ]; then
          kill $(cat backend/server.pid) 2>/dev/null || true
        fi

  # --- Load Tests (Nightly/Manual) ---
  load-tests-nightly:
    name: ‚ö° Load Tests (k6)
    runs-on: ubuntu-latest
    timeout-minutes: 35
    needs: [security, integration]
    if: always() && (github.event_name == 'schedule' || github.event_name == 'workflow_dispatch' || (github.event_name == 'push' && github.ref == 'refs/heads/main'))
    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_DB: clinicdb
          POSTGRES_USER: clinic
          POSTGRES_PASSWORD: clinicpwd
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U clinic -d clinicdb"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10
    env:
      DATABASE_URL: postgresql+psycopg://clinic:clinicpwd@localhost:5432/clinicdb
      CORS_DISABLE: '1'
      WS_DEV_ALLOW: '1'
      TARGET_RPS: '30'
      PYTHONIOENCODING: 'utf-8'
      PYTHONUTF8: '1'

    steps:
    - uses: actions/checkout@v4

    - name: üêç Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: üìà Setup k6
      uses: grafana/setup-k6-action@v1

    - name: üì¶ Install backend dependencies
      run: |
        cd backend
        pip install --upgrade pip
        pip install -r requirements.txt

    - name: üóÑÔ∏è Prepare database
      run: |
        cd backend
        python - <<'PY'
        import os
        import time
        from sqlalchemy import create_engine, text

        engine = create_engine(os.environ["DATABASE_URL"])
        for i in range(30):
            try:
                with engine.connect() as conn:
                    conn.execute(text("SELECT 1"))
                print("‚úÖ Postgres ready")
                break
            except Exception as e:
                if i == 29:
                    raise
                print(f"Attempt {i + 1}/30: {e}")
                time.sleep(2)
        PY
        alembic upgrade head

    - name: üöÄ Start API for load test
      run: |
        set +e
        mkdir -p artifacts/load
        cd backend
        nohup uvicorn app.main:app --host 127.0.0.1 --port 8000 > load_server.log 2>&1 &
        echo $! > load_server.pid
        API_READY=0
        for i in {1..30}; do
          if curl -s -f "http://127.0.0.1:8000/api/v1/health" > /dev/null 2>&1; then
            echo "‚úÖ API ready for load test"
            API_READY=1
            break
          fi
          sleep 2
        done
        echo "LOAD_API_READY=$API_READY" >> $GITHUB_ENV
        if [ "$API_READY" -ne 1 ]; then
          echo "::warning::API did not start for load test. k6 step will be marked as failed with fallback artifacts."
          tail -100 load_server.log || true
        fi
        exit 0

    - name: ‚ö° Run k6 baseline scenario
      run: |
        set +e
        mkdir -p artifacts/load
        if [ "${LOAD_API_READY:-0}" -ne 1 ]; then
          echo "::warning::Skipping k6 execution because API was not ready."
          K6_EXIT=1
        else
          export BASE_URL=http://127.0.0.1:8000
          export TARGET_RPS=${TARGET_RPS}
          k6 run ops/load/clinic_core.js \
            --summary-export=artifacts/load/k6-summary.json \
            > artifacts/load/k6-run.log 2>&1
          K6_EXIT=$?
        fi
        echo "K6_EXIT_CODE=$K6_EXIT" >> $GITHUB_ENV
        if [ ! -f artifacts/load/k6-summary.json ]; then
          echo "::warning::k6 summary was not generated; writing fallback summary."
          cat > artifacts/load/k6-summary.json <<'JSON'
        {"error":"k6 summary was not generated","metrics":{}}
        JSON
          echo "K6_SUMMARY_MISSING=1" >> $GITHUB_ENV
        else
          echo "K6_SUMMARY_MISSING=0" >> $GITHUB_ENV
        fi
        exit 0

    - name: üö¶ Check load regression
      run: |
        set +e
        python ops/scripts/check_load_regression.py \
          --summary artifacts/load/k6-summary.json \
          --baseline ops/load/baseline_targets.json \
          --report artifacts/load/load-regression-report.md
        REG_EXIT=$?
        echo "LOAD_REGRESSION_EXIT_CODE=$REG_EXIT" >> $GITHUB_ENV
        if [ $REG_EXIT -ne 0 ] && [ ! -f artifacts/load/load-regression-report.md ]; then
          cat > artifacts/load/load-regression-report.md <<'MD'
        # Load Test Regression Report

        - Status: FAIL
        - Reason: Regression check did not produce a report.
        MD
        fi
        exit 0

    - name: üì§ Upload load artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: load-test-report
        path: |
          artifacts/load/k6-summary.json
          artifacts/load/load-regression-report.md
          artifacts/load/k6-run.log
        if-no-files-found: warn

    - name: üõë Stop API
      if: always()
      run: |
        if [ -f backend/load_server.pid ]; then
          kill $(cat backend/load_server.pid) 2>/dev/null || true
        fi

    - name: üö® Enforce load gate
      run: |
        K6_EXIT=${K6_EXIT_CODE:-1}
        REG_EXIT=${LOAD_REGRESSION_EXIT_CODE:-1}
        SUMMARY_MISSING=${K6_SUMMARY_MISSING:-1}

        if [ ! -f artifacts/load/load-regression-report.md ]; then
          cat > artifacts/load/load-regression-report.md <<'MD'
        # Load Test Regression Report

        - Status: FAIL
        - Reason: load-regression-report.md missing after checks.
        MD
          REG_EXIT=1
        fi

        echo "k6_exit=$K6_EXIT, regression_exit=$REG_EXIT, summary_missing=$SUMMARY_MISSING"
        if [ "$K6_EXIT" -ne 0 ] || [ "$REG_EXIT" -ne 0 ] || [ "$SUMMARY_MISSING" -ne 0 ]; then
          echo "::error::Load gate failed."
          exit 1
        fi

  # --- DAST (Nightly) ---
  dast-zap-nightly:
    name: üõ°Ô∏è DAST ZAP (Nightly)
    runs-on: ubuntu-latest
    timeout-minutes: 30
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_DB: clinicdb
          POSTGRES_USER: clinic
          POSTGRES_PASSWORD: clinicpwd
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U clinic -d clinicdb"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10
    env:
      DATABASE_URL: postgresql+psycopg://clinic:clinicpwd@localhost:5432/clinicdb
      CORS_DISABLE: '1'
      WS_DEV_ALLOW: '1'

    steps:
    - uses: actions/checkout@v4

    - name: üêç Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'

    - name: üì¶ Install backend dependencies
      run: |
        cd backend
        pip install --upgrade pip
        pip install -r requirements.txt

    - name: üóÑÔ∏è Prepare database
      run: |
        cd backend
        python - <<'PY'
        import os
        import time
        from sqlalchemy import create_engine, text

        engine = create_engine(os.environ["DATABASE_URL"])
        for i in range(30):
            try:
                with engine.connect() as conn:
                    conn.execute(text("SELECT 1"))
                print("‚úÖ Postgres ready")
                break
            except Exception as e:
                if i == 29:
                    raise
                print(f"Attempt {i + 1}/30: {e}")
                time.sleep(2)
        PY
        alembic upgrade head

    - name: üöÄ Start API for DAST
      run: |
        cd backend
        nohup uvicorn app.main:app --host 127.0.0.1 --port 8000 > zap_server.log 2>&1 &
        echo $! > zap_server.pid
        for i in {1..30}; do
          if curl -s -f "http://127.0.0.1:8000/api/v1/health" > /dev/null 2>&1; then
            echo "‚úÖ API is ready for ZAP scan"
            exit 0
          fi
          sleep 2
        done
        echo "‚ùå API did not start"
        tail -100 zap_server.log || true
        exit 1

    - name: üîé Run ZAP baseline scan
      run: |
        mkdir -p zap-report
        docker run --rm --network=host \
          -v ${{ github.workspace }}/zap-report:/zap/wrk \
          ghcr.io/zaproxy/zaproxy:stable \
          zap-baseline.py \
          -t http://127.0.0.1:8000 \
          -J /zap/wrk/zap-report.json \
          -r /zap/wrk/zap-report.html \
          -w /zap/wrk/zap-warnings.md \
          -m 5

    - name: üö¶ Enforce DAST policy
      run: |
        python - <<'PY'
        import json
        from pathlib import Path

        report = json.loads(Path("zap-report/zap-report.json").read_text(encoding="utf-8"))
        high = 0
        medium = 0

        for site in report.get("site", []):
          for alert in site.get("alerts", []):
            risk = str(alert.get("riskcode", "0"))
            if risk == "3":
              high += 1
            elif risk == "2":
              medium += 1

        print(f"ZAP alerts: high={high}, medium={medium}")
        if high > 0 or medium > 0:
          raise SystemExit(1)
        PY

    - name: üì§ Upload ZAP artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: zap-nightly-report
        path: zap-report/
        if-no-files-found: warn

    - name: üõë Stop API
      if: always()
      run: |
        if [ -f backend/zap_server.pid ]; then
          kill $(cat backend/zap_server.pid) 2>/dev/null || true
        fi

  # --- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è ---
  docs:
    name: üìö –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
    runs-on: ubuntu-latest
    timeout-minutes: 10
    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_DB: clinicdb
          POSTGRES_USER: clinic
          POSTGRES_PASSWORD: clinicpwd
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U clinic -d clinicdb"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10
    env:
      DATABASE_URL: postgresql+psycopg://clinic:clinicpwd@localhost:5432/clinicdb
      CORS_DISABLE: '1'
      WS_DEV_ALLOW: '1'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: üêç –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
      run: |
        cd backend
        pip install --upgrade pip
        pip install -r requirements.txt
        pip install sphinx sphinx-rtd-theme
    
    - name: üìö –ì–µ–Ω–µ—Ä–∞—Ü–∏—è API –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
      run: |
        cd backend
        echo "‚è≥ –û–∂–∏–¥–∞–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å Postgres..."
        python - <<'PY'
        import os
        import time
        from sqlalchemy import create_engine, text

        url = os.environ["DATABASE_URL"]
        engine = create_engine(url)
        for i in range(30):
            try:
                with engine.connect() as conn:
                    conn.execute(text("SELECT 1"))
                print("‚úÖ Postgres ready")
                break
            except Exception as e:
                if i == 29:
                    raise
                print(f"Attempt {i + 1}/30: {e}")
                time.sleep(2)
        PY
        alembic upgrade head
        alembic current

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        if [ ! -f "app/main.py" ]; then
          echo "‚ùå –§–∞–π–ª app/main.py –Ω–µ –Ω–∞–π–¥–µ–Ω"
          exit 1
        fi
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º OpenAPI —Å—Ö–µ–º—É —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
        python -c "
        import sys
        import os
        import traceback
        
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
            sys.path.insert(0, '.')
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –ü–ï–†–ï–î –∏–º–ø–æ—Ä—Ç–æ–º
            os.environ['DATABASE_URL'] = 'postgresql+psycopg://clinic:clinicpwd@localhost:5432/clinicdb'
            os.environ['CORS_DISABLE'] = '1'
            os.environ['WS_DEV_ALLOW'] = '1'
            
            print('üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞')
            print(f'üìã DATABASE_URL: {os.environ.get(\"DATABASE_URL\")}')
            
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
            print('üì¶ –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º app.main...')
            from app.main import app
            import json
            
            print('‚úÖ –ò–º–ø–æ—Ä—Ç app.main —É—Å–ø–µ—à–µ–Ω')
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å—Ö–µ–º—É
            print('üìù –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º OpenAPI —Å—Ö–µ–º—É...')
            openapi_schema = app.openapi()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ö–µ–º—É
            with open('openapi.json', 'w', encoding='utf-8') as f:
                json.dump(openapi_schema, f, indent=2, ensure_ascii=False)
            
            print('‚úÖ OpenAPI —Å—Ö–µ–º–∞ —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ')
            print(f'üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {os.path.getsize(\"openapi.json\")} –±–∞–π—Ç')
            
        except Exception as e:
            print(f'‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏: {e}')
            print('üìã –î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏:')
            traceback.print_exc()
            
            # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é —Å—Ö–µ–º—É –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
            print('‚ö†Ô∏è –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é —Å—Ö–µ–º—É...')
            minimal_schema = {
                'openapi': '3.0.0',
                'info': {
                    'title': 'Clinic API', 
                    'version': '1.0.0',
                    'description': 'API documentation - generation failed'
                },
                'paths': {},
                'components': {'schemas': {}}
            }
            import json
            with open('openapi.json', 'w', encoding='utf-8') as f:
                json.dump(minimal_schema, f, indent=2, ensure_ascii=False)
            print('‚úÖ –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è OpenAPI —Å—Ö–µ–º–∞ —Å–æ–∑–¥–∞–Ω–∞')
        "
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å–æ–∑–¥–∞–ª—Å—è
        if [ -f "openapi.json" ]; then
          echo "‚úÖ –§–∞–π–ª openapi.json —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ"
          echo "üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: $(wc -c < openapi.json) –±–∞–π—Ç"
        else
          echo "‚ùå –§–∞–π–ª openapi.json –Ω–µ —Å–æ–∑–¥–∞–Ω"
          exit 1
        fi
    
    - name: üì§ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
      uses: actions/upload-artifact@v4
      with:
        name: api-docs
        path: backend/openapi.json

  # --- Deploy Staging ---
  deploy-staging:
    name: üöÄ Deploy Staging
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: [docker, security, docs, integration]
    if: github.event_name == 'push' && github.ref == 'refs/heads/develop'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: üöÄ Deploy to Staging
      run: |
        echo "üöÄ –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –≤ staging –æ–∫—Ä—É–∂–µ–Ω–∏–µ"
        echo "‚úÖ –í—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã"
        echo "üì¶ Docker –æ–±—Ä–∞–∑—ã —Å–æ–±—Ä–∞–Ω—ã"
        echo "üîí Security —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ"
        echo "üîó –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã"

  # --- Deploy Production ---
  deploy-production:
    name: üåü Deploy Production
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: [docker, security, docs, integration]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    environment:
      name: production
    
    steps:
    - uses: actions/checkout@v4
    
    - name: üåü Deploy to Production
      run: |
        echo "üåü –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –≤ production –æ–∫—Ä—É–∂–µ–Ω–∏–µ"
        echo "‚úÖ –í—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã"
        echo "üì¶ Docker –æ–±—Ä–∞–∑—ã —Å–æ–±—Ä–∞–Ω—ã"
        echo "üîí Security —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ"
        echo "üîó –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã"
        echo "üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∞"

  # --- –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è ---
  notifications:
    name: üìß –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
    runs-on: ubuntu-latest
    needs: [deploy-staging, deploy-production]
    if: always()
    
    steps:
    - name: üìß –û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π
      run: |
        if [ "${{ needs.deploy-staging.result }}" == "success" ] || [ "${{ needs.deploy-production.result }}" == "success" ]; then
          echo "‚úÖ –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ"
          echo "üìß –£–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã"
        else
          echo "‚ùå –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ"
        fi

